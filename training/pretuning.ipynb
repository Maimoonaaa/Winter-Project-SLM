{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZWlmtZIz2Pu",
        "outputId": "ee846edc-018c-4c95-8bb7-e849de00bada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# !mkdir -p /content/drive/MyDrive/slm\n",
        "# !cd /content/drive/MyDrive/slm\n",
        "# !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "# !pip install -q datasets tiktoken tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "6a071fe28d094fedbcddc1282e66f737",
            "154dbd5c8d5043dd8a951d134a31bd2e",
            "c0fd84562d894577a2042d6c25ef0a67",
            "81958678710141dfada541aa8186e2dd",
            "f770d490fa6946c18f67ca98fb1c51f9",
            "f764c04d004e415b9462ec9878529fad",
            "aacd7de0e74d4cd3ad4504e26f5490d4",
            "172225679acc42e3960fdb0da16187e5",
            "f6b514d7652249859993486dfd6afc2c",
            "1deea6da149c405d844379c16a464162",
            "ef553bddf8f04f8b96ef6f933c01c51b",
            "95b5f5311bad42679baf9b7ef9703769",
            "794234febfdf4e76a9b3eceee71557f4",
            "878565641d3c4fd5a94ea2a81f88d0e2",
            "8243df682ae1478996442f885cb18d24",
            "a0c5bb646fa64392ba60cd13b2e2f5b3",
            "72199fd389594b559621acf39b045a2d",
            "eca0316f489c4efe98906b12a1d0655e",
            "dfd5fe61dc934631a19ceca21adf2f9a",
            "e5bf1be6b3f04849b0c53b5b6c43d10b",
            "a27a4661a2d14c729d40b39108bf762d",
            "8627d1f060514918b2a9cdfe767d6c54"
          ]
        },
        "id": "qxEmlzJzxSjp",
        "outputId": "ee9ace7f-258f-40fa-99c2-4fb565ae8ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading 80,000 samples (streaming)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a071fe28d094fedbcddc1282e66f737",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b5f5311bad42679baf9b7ef9703769",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing & splitting\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80000/80000 [01:10<00:00, 1126.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing train.bin (89,498,669 tokens)\n",
            "Writing test.bin (934,461 tokens)\n",
            "Dataset preparation complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "from datasets import load_dataset\n",
        "\n",
        "SUBSET_PERCENT = 1        # 1% of OpenWebText\n",
        "VAL_FRACTION = 0.01       # 1% of subset for validation\n",
        "\n",
        "out_dir = \"data\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# ---- compute absolute sample count ----\n",
        "# OpenWebText ≈ 8M examples\n",
        "TOTAL_EXAMPLES = 8_000_000\n",
        "NUM_SAMPLES = int(TOTAL_EXAMPLES * SUBSET_PERCENT / 100)\n",
        "NUM_VAL = int(NUM_SAMPLES * VAL_FRACTION)\n",
        "NUM_TRAIN = NUM_SAMPLES - NUM_VAL\n",
        "\n",
        "print(f\"Loading {NUM_SAMPLES:,} samples (streaming)\")\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"openwebtext\",\n",
        "    split=\"train\",\n",
        "    streaming=True\n",
        ")\n",
        "\n",
        "dataset = dataset.take(NUM_SAMPLES)\n",
        "\n",
        "train_tokens = []\n",
        "val_tokens = []\n",
        "\n",
        "def encode(text):\n",
        "    ids = enc.encode(text)\n",
        "    ids.append(enc.eot_token)\n",
        "    return ids\n",
        "\n",
        "print(\"Tokenizing & splitting\")\n",
        "\n",
        "for i, ex in enumerate(tqdm(dataset, total=NUM_SAMPLES)):\n",
        "    ids = encode(ex[\"text\"])\n",
        "    if i < NUM_VAL:\n",
        "        val_tokens.extend(ids)\n",
        "    else:\n",
        "        train_tokens.extend(ids)\n",
        "\n",
        "# ---- write binaries ----\n",
        "def write_bin(path, tokens):\n",
        "    arr = np.memmap(\n",
        "        path,\n",
        "        dtype=np.uint16,\n",
        "        mode=\"w+\",\n",
        "        shape=(len(tokens),)\n",
        "    )\n",
        "    arr[:] = np.array(tokens, dtype=np.uint16)\n",
        "    arr.flush()\n",
        "\n",
        "print(f\"Writing train.bin ({len(train_tokens):,} tokens)\")\n",
        "write_bin(os.path.join(out_dir, \"train.bin\"), train_tokens)\n",
        "\n",
        "print(f\"Writing test.bin ({len(val_tokens):,} tokens)\")\n",
        "write_bin(os.path.join(out_dir, \"test.bin\"), val_tokens)\n",
        "\n",
        "print(\"Dataset preparation complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S6mbgoS90L3A"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, ndim, bias=True):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim)) #element wise scaling\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "# RoPE\n",
        "def rotate_half(x):\n",
        "    x1 = x[..., : x.shape[-1] // 2]\n",
        "    x2 = x[..., x.shape[-1] // 2 :]\n",
        "    return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "def apply_rope(q, k, cos, sin):\n",
        "    q = (q * cos) + (rotate_half(q) * sin)\n",
        "    k = (k * cos) + (rotate_half(k) * sin)\n",
        "    return q, k\n",
        "\n",
        "class RotaryEmbedding:\n",
        "    def __init__(self, dim, max_seq_len):\n",
        "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register(inv_freq, max_seq_len)\n",
        "\n",
        "    def register(self, inv_freq, max_seq_len):\n",
        "        t = torch.arange(max_seq_len)\n",
        "        freqs = torch.einsum(\"i,j->ij\", t, inv_freq)\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)\n",
        "        self.cos = emb.cos()[None, None, :, :]\n",
        "        self.sin = emb.sin()[None, None, :, :]\n",
        "\n",
        "    def get(self, seq_len, device):\n",
        "        return (\n",
        "            self.cos[:, :, :seq_len, :].to(device),\n",
        "            self.sin[:, :, :seq_len, :].to(device),\n",
        "        )\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embed % config.n_head == 0\n",
        "\n",
        "        self.n_head = config.n_head\n",
        "        self.head_dim = config.n_embed // config.n_head\n",
        "        self.dropout = config.dropout\n",
        "\n",
        "        self.qkv = nn.Linear(config.n_embed, 3 * config.n_embed, bias=config.bias)\n",
        "        self.proj = nn.Linear(config.n_embed, config.n_embed, bias=config.bias)\n",
        "\n",
        "        self.rope = RotaryEmbedding(self.head_dim, config.block_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        q = q.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        cos, sin = self.rope.get(T, x.device)\n",
        "        q, k = apply_rope(q, k, cos, sin)\n",
        "\n",
        "        # FlashAttention (automatic if supported)\n",
        "        out = F.scaled_dot_product_attention(\n",
        "            q, k, v,\n",
        "            dropout_p=self.dropout if self.training else 0.0,\n",
        "            is_causal=True\n",
        "        )\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.proj(out)\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(config.n_embed, 4 * config.n_embed, bias=config.bias)\n",
        "        self.proj = nn.Linear(4 * config.n_embed, config.n_embed, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.proj(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = LayerNorm(config.n_embed, config.bias)\n",
        "        self.attn = MultiHeadAttention(config)\n",
        "        self.ln2 = LayerNorm(config.n_embed, config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class SLMconfig:\n",
        "    vocab_size: int = 50257\n",
        "    block_size: int = 64\n",
        "    n_layer: int = 4\n",
        "    n_head: int = 6\n",
        "    n_embed: int = 384\n",
        "    dropout: float = 0.1\n",
        "    bias: bool = False\n",
        "\n",
        "class SLM(nn.Module):\n",
        "    def __init__(self, config: SLMconfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.token_emb = nn.Embedding(config.vocab_size, config.n_embed)\n",
        "        self.drop = nn.Dropout(config.dropout)\n",
        "\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
        "        self.ln_f = LayerNorm(config.n_embed, config.bias)\n",
        "\n",
        "        self.lm_head = nn.Linear(config.n_embed, config.vocab_size, bias=False)\n",
        "        self.token_emb.weight = self.lm_head.weight  # weight tying\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        print(f\"Number of parameters: {self.num_params()/1e6:.2f}M\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def num_params(self):\n",
        "        return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        assert T <= self.config.block_size\n",
        "\n",
        "        x = self.token_emb(idx)\n",
        "        x = self.drop(x)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                targets.view(-1),\n",
        "                ignore_index=-1\n",
        "            )\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -self.config.block_size :]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, top_k)\n",
        "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_idx = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, next_idx), dim=1)\n",
        "\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIw-peQuplMq",
        "outputId": "000e051d-8d46-42af-dc82-4b680b239219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of parameters: 26.38M\n",
            "Starting training...\n",
            "step 0 | train 10.9084 | val 10.9070\n",
            "[✓] checkpoint saved at step 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "# =========================\n",
        "# DEVICE\n",
        "# =========================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# TRAINING HYPERPARAMS\n",
        "# =========================\n",
        "batch_size = 8\n",
        "block_size = 256\n",
        "gradient_accum_steps = 8\n",
        "max_iters = 20000\n",
        "eval_interval = 1000\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 200\n",
        "\n",
        "# =========================\n",
        "# CHECKPOINT CONFIG\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "CKPT_ROOT = Path(\"/content/drive/MyDrive/slm_checkpoints\")\n",
        "CKPT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "SAVE_EVERY = eval_interval\n",
        "MAX_KEEP = 3\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING\n",
        "# =========================\n",
        "def load_data(split):\n",
        "    return np.memmap(\n",
        "        f\"/content/data/{split}.bin\",\n",
        "        dtype=np.uint16,\n",
        "        mode=\"r\"\n",
        "    )\n",
        "\n",
        "train_data = load_data(\"train\")\n",
        "val_data   = load_data(\"test\")\n",
        "\n",
        "def get_batch(data):\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([\n",
        "        torch.from_numpy(data[i:i+block_size].astype(np.int64))\n",
        "        for i in ix\n",
        "    ])\n",
        "    y = torch.stack([\n",
        "        torch.from_numpy(data[i+1:i+1+block_size].astype(np.int64))\n",
        "        for i in ix\n",
        "    ])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "config = SLMconfig(\n",
        "    vocab_size=50257,\n",
        "    block_size=block_size,\n",
        "    n_layer=4,\n",
        "    n_head=6,\n",
        "    n_embed=384,\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "model = SLM(config).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=0.06\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# LR SCHEDULE\n",
        "# =========================\n",
        "warmup_steps = int(0.05 * max_iters)\n",
        "min_lr = learning_rate * 0.1\n",
        "\n",
        "def get_lr(step):\n",
        "    if step < warmup_steps:\n",
        "        return learning_rate * step / warmup_steps\n",
        "    progress = (step - warmup_steps) / (max_iters - warmup_steps)\n",
        "    cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))\n",
        "    return min_lr + cosine_decay * (learning_rate - min_lr)\n",
        "\n",
        "# =========================\n",
        "# EVAL\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    model.eval()\n",
        "    out = {}\n",
        "    for split, data in [(\"train\", train_data), (\"val\", val_data)]:\n",
        "        losses = []\n",
        "        for _ in range(eval_iters):\n",
        "            X, Y = get_batch(data)\n",
        "            _, loss = model(X, Y)\n",
        "            losses.append(loss.item())\n",
        "        out[split] = sum(losses) / len(losses)\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "# =========================\n",
        "# ATOMIC SAVE\n",
        "# =========================\n",
        "def atomic_save(obj, path):\n",
        "    tmp = path.with_suffix(\".tmp\")\n",
        "    torch.save(obj, tmp, _use_new_zipfile_serialization=False)\n",
        "    os.replace(tmp, path)\n",
        "\n",
        "def save_checkpoint(step):\n",
        "    ckpt_dir = CKPT_ROOT / f\"step_{step}\"\n",
        "    ckpt_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    atomic_save(model.state_dict(), ckpt_dir / \"model.pt\")\n",
        "    atomic_save(optimizer.state_dict(), ckpt_dir / \"optimizer.pt\")\n",
        "    atomic_save({\n",
        "    \"step\": step,\n",
        "    \"torch_rng\": torch.get_rng_state(),\n",
        "    \"cuda_rng\": torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None}, ckpt_dir / \"meta.pt\")\n",
        "\n",
        "    # cleanup old\n",
        "    ckpts = sorted(CKPT_ROOT.glob(\"step_*\"), key=lambda x: int(x.name.split(\"_\")[1]))\n",
        "    for old in ckpts[:-MAX_KEEP]:\n",
        "        for f in old.iterdir():\n",
        "            f.unlink()\n",
        "        old.rmdir()\n",
        "\n",
        "    print(f\"[✓] checkpoint saved at step {step}\")\n",
        "\n",
        "# =========================\n",
        "# RESUME (AUTO)\n",
        "# =========================\n",
        "def try_resume():\n",
        "    ckpts = sorted(CKPT_ROOT.glob(\"step_*\"), key=lambda x: int(x.name.split(\"_\")[1]))\n",
        "    if not ckpts:\n",
        "        return 0\n",
        "\n",
        "    latest = ckpts[-1]\n",
        "    print(f\"[↻] resuming from {latest.name}\")\n",
        "\n",
        "    model.load_state_dict(torch.load(latest / \"model.pt\", map_location=device))\n",
        "    optimizer.load_state_dict(torch.load(latest / \"optimizer.pt\", map_location=device))\n",
        "\n",
        "    meta = torch.load(latest / \"meta.pt\", map_location=\"cpu\",weights_only=False)\n",
        "    torch.set_rng_state(meta[\"torch_rng\"])\n",
        "    if meta[\"cuda_rng\"] is not None and torch.cuda.is_available():\n",
        "        torch.cuda.set_rng_state_all(meta[\"cuda_rng\"])\n",
        "\n",
        "    return meta[\"step\"] + 1\n",
        "\n",
        "# =========================\n",
        "# TRAIN LOOP\n",
        "# =========================\n",
        "print(\"Starting training...\")\n",
        "start_step = try_resume()\n",
        "t0 = time.time()\n",
        "\n",
        "for step in range(start_step, max_iters):\n",
        "\n",
        "    lr = get_lr(step)\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    for _ in range(gradient_accum_steps):\n",
        "        X, Y = get_batch(train_data)\n",
        "        _, loss = model(X, Y)\n",
        "        (loss / gradient_accum_steps).backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(\n",
        "            f\"step {step} | \"\n",
        "            f\"train {losses['train']:.4f} | \"\n",
        "            f\"val {losses['val']:.4f}\"\n",
        "        )\n",
        "        save_checkpoint(step)\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8EPZHP1nAJK"
      },
      "source": [
        "before rerunning, delete thid folder using-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fC1kK8PnGk-"
      },
      "outputs": [],
      "source": [
        "# -rm -rf /content/drive/MyDrive/slm_checkpoints/*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "154dbd5c8d5043dd8a951d134a31bd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f764c04d004e415b9462ec9878529fad",
            "placeholder": "​",
            "style": "IPY_MODEL_aacd7de0e74d4cd3ad4504e26f5490d4",
            "value": "Resolving data files: 100%"
          }
        },
        "172225679acc42e3960fdb0da16187e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1deea6da149c405d844379c16a464162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a071fe28d094fedbcddc1282e66f737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_154dbd5c8d5043dd8a951d134a31bd2e",
              "IPY_MODEL_c0fd84562d894577a2042d6c25ef0a67",
              "IPY_MODEL_81958678710141dfada541aa8186e2dd"
            ],
            "layout": "IPY_MODEL_f770d490fa6946c18f67ca98fb1c51f9"
          }
        },
        "72199fd389594b559621acf39b045a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794234febfdf4e76a9b3eceee71557f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72199fd389594b559621acf39b045a2d",
            "placeholder": "​",
            "style": "IPY_MODEL_eca0316f489c4efe98906b12a1d0655e",
            "value": "Resolving data files: 100%"
          }
        },
        "81958678710141dfada541aa8186e2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1deea6da149c405d844379c16a464162",
            "placeholder": "​",
            "style": "IPY_MODEL_ef553bddf8f04f8b96ef6f933c01c51b",
            "value": " 80/80 [00:00&lt;00:00,  6.11it/s]"
          }
        },
        "8243df682ae1478996442f885cb18d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a27a4661a2d14c729d40b39108bf762d",
            "placeholder": "​",
            "style": "IPY_MODEL_8627d1f060514918b2a9cdfe767d6c54",
            "value": " 80/80 [00:00&lt;00:00, 2590.06it/s]"
          }
        },
        "8627d1f060514918b2a9cdfe767d6c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "878565641d3c4fd5a94ea2a81f88d0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd5fe61dc934631a19ceca21adf2f9a",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5bf1be6b3f04849b0c53b5b6c43d10b",
            "value": 80
          }
        },
        "95b5f5311bad42679baf9b7ef9703769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_794234febfdf4e76a9b3eceee71557f4",
              "IPY_MODEL_878565641d3c4fd5a94ea2a81f88d0e2",
              "IPY_MODEL_8243df682ae1478996442f885cb18d24"
            ],
            "layout": "IPY_MODEL_a0c5bb646fa64392ba60cd13b2e2f5b3"
          }
        },
        "a0c5bb646fa64392ba60cd13b2e2f5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a27a4661a2d14c729d40b39108bf762d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aacd7de0e74d4cd3ad4504e26f5490d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0fd84562d894577a2042d6c25ef0a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172225679acc42e3960fdb0da16187e5",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6b514d7652249859993486dfd6afc2c",
            "value": 80
          }
        },
        "dfd5fe61dc934631a19ceca21adf2f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5bf1be6b3f04849b0c53b5b6c43d10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eca0316f489c4efe98906b12a1d0655e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef553bddf8f04f8b96ef6f933c01c51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6b514d7652249859993486dfd6afc2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f764c04d004e415b9462ec9878529fad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f770d490fa6946c18f67ca98fb1c51f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
